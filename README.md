ğŸ“˜ README â€” AgrÃ©gateur RSS Qualiopi & Dashboard Web -
Ce dÃ©pÃ´t contient deux projets complÃ©mentaires :

Un projet Python (basÃ© sur Poetry)
â†’ Scraper COSMOS + gÃ©nÃ©rateur RSS + outils dâ€™analyse

Un projet Web statique  
â†’ AgrÃ©gateur RSS local + interface de veille + dashboard des logs
â†’ DÃ©ployÃ© automatiquement via GitHub Pages

Les deux projets coopÃ¨rent grÃ¢ce Ã  un pipeline GitHub Actions qui gÃ©nÃ¨re automatiquement les flux RSS consolidÃ©s.

ğŸŸ¦ 1) Projet Python : Scraper & GÃ©nÃ©rateur RSS
ğŸ“ RÃ©pertoire : src/rss_qualiopi/  
ğŸ“„ Fichiers principaux :

scraper.py  
â†’ Scrape les donnÃ©es COSMOS (ou autres sources internes)
â†’ GÃ©nÃ¨re un flux RSS local : docs/xml/rss_cosmos.xml

rss_generator.py  
â†’ Outils gÃ©nÃ©riques pour produire des flux RSS

json_logger.py  
â†’ SystÃ¨me de logs JSONL compatible avec le dashboard web

main.py  
â†’ Point dâ€™entrÃ©e possible pour exÃ©cuter le pipeline Python localement

export_csv.py, diff.py  
â†’ Outils dâ€™analyse et dâ€™export

ğŸ“¦ Gestion des dÃ©pendances :  
Le projet utilise Poetry :

bash
poetry install
poetry run python src/rss_qualiopi/scraper.py
ğŸ“ Sortie du scraper :  
Le scraper Ã©crit directement dans le site web, dans :

Code
docs/xml/rss_cosmos.xml
Ce fichier est ensuite intÃ©grÃ© dans lâ€™agrÃ©gateur web.

ğŸŸ¦ 2) Projet Web : AgrÃ©gateur RSS statique
ğŸ“ RÃ©pertoire : docs/  
Ce dossier est la racine du site GitHub Pages.

ğŸ”¹ FonctionnalitÃ©s
Lecture de tous les flux RSS locaux (gÃ©nÃ©rÃ©s automatiquement)

Consolidation par thÃ©matique :

LÃ©gal & rÃ©glementaire

PÃ©dagogique & technologique

MÃ©tiers & compÃ©tences

Affichage :

Derniers articles

ActivitÃ© rÃ©cente (graphique Chart.js)

Recherche instantanÃ©e

Sources vides affichÃ©es mais grisÃ©es

Dashboard des logs JSONL

ğŸ”¹ Fichiers clÃ©s
index.html  
â†’ Interface principale de veille

dashboard.html  
â†’ Visualisation des logs (filtres + graphique)

aggregate.py  
â†’ AgrÃ©gateur RSS local
â†’ GÃ©nÃ¨re :

docs/xml/rss_*.xml

docs/xml/flux_*.xml

docs/xml/rss_final.xml

docs/xml/sources.json

assets/js/*.js  
â†’ Scripts dâ€™affichage, parsing RSS, recherche, graphiques

xml/  
â†’ Tous les flux gÃ©nÃ©rÃ©s automatiquement

ğŸŸ¦ 3) Pipeline GitHub Actions
ğŸ“ Fichier : .github/workflows/generate-rss.yml

Le pipeline :

Installe Poetry

Installe les dÃ©pendances du projet Python

ExÃ©cute le scraper COSMOS

ExÃ©cute lâ€™agrÃ©gateur RSS

Met Ã  jour automatiquement les fichiers dans docs/xml/

Pousse les modifications sur main

GitHub Pages met Ã  jour le site

ğŸ”¹ ExÃ©cution automatique
Toutes les heures (cron: "0 * * * *")

Ou manuellement via lâ€™interface GitHub

ğŸŸ¦ 4) DÃ©ploiement GitHub Pages
Le site est servi depuis :

Code
/docs
Ce qui permet :

un site statique lÃ©ger

aucune dÃ©pendance serveur

un hÃ©bergement gratuit

une mise Ã  jour automatique via GitHub Actions

ğŸŸ¦ 5) DÃ©veloppement local
Installer les dÃ©pendances Python
bash
poetry install
Lancer le scraper
bash
poetry run python src/rss_qualiopi/scraper.py
Lancer lâ€™agrÃ©gateur
bash
poetry run python docs/aggregate.py
Ouvrir le site localement
Ouvrir simplement :

Code
docs/index.html
docs/dashboard.html
ğŸŸ¦ 6) Structure du dÃ©pÃ´t
Code
.
â”œâ”€â”€ docs/                     # Site web statique (GitHub Pages)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ aggregate.py
â”‚   â”œâ”€â”€ sources.py
â”‚   â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ xml/                  # Flux gÃ©nÃ©rÃ©s automatiquement
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/rss_qualiopi/         # Projet Python (scraper + outils)
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ rss_generator.py
â”‚   â”œâ”€â”€ json_logger.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .github/workflows/        # Pipeline GitHub Actions
â”‚   â””â”€â”€ generate-rss.yml
â”‚
â”œâ”€â”€ pyproject.toml            # Configuration Poetry
â””â”€â”€ README.md
ğŸŸ¦ 7) Licence & contact
Projet dÃ©veloppÃ© par PhiC13  
Objectif : automatiser la veille Qualiopi / rÃ©glementaire / pÃ©dagogique.